<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Are Police Biased Against Black Persons</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Projects</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Customer-Personality-Analysis-read.html">Customer Personality Data</a>
</li>
<li>
  <a href="Open_Police_CA.html">Open Policing Analysis</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Are Police Biased Against Black Persons</h1>

</div>


<div id="packages" class="section level2">
<h2>Packages</h2>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeSh0aWR5dmVyc2UpXG5saWJyYXJ5KFJTUUxpdGUpXG5saWJyYXJ5KGRicGx5cilcbmxpYnJhcnkocmVhZHIpXG5saWJyYXJ5KERCSSlcbmxpYnJhcnkoZGV2dG9vbHMpXG5saWJyYXJ5KGluYm9ydXRpbHMpICMgZm9yIGxhcmdlIGZpbGVzXG5saWJyYXJ5KHJpbylcbmxpYnJhcnkoa25pdHIpXG5saWJyYXJ5KGJyb29tKVxuYGBgIn0= -->
<pre class="r"><code>library(tidyverse)
library(RSQLite)
library(dbplyr)
library(readr)
library(DBI)
library(devtools)
library(inborutils) # for large files
library(rio)
library(knitr)
library(broom)</code></pre>
<!-- rnb-source-end -->
</div>
<div id="reading-the-data" class="section level2">
<h2>Reading the Data</h2>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuIyBzaG91bGRuJ3QgbmVlZCB0aGlzIGFmdGVyIHdyaXRpbmcgdG8gU1FMaXRlIGRiXG4jIElkZWFzIGZvciBsYXJnZXIgREIgaW4gY3N2OiBiaWdtYXRyaXggcGFja2FnZVxuIyBkYXQgPC0gcmVhZFJEUyhcIkM6L1VzZXJzL0NocmlzL09uZURyaXZlL1IgcHJvamVjdC9PcGVuIFBvbGljaW5nL3lnODIxamY4NjExX2NhX3N0YXRld2lkZV8yMDIwXzA0XzAxLnJkc1wiKVxuYGBgIn0= -->
<pre class="r"><code># shouldn&#39;t need this after writing to SQLite db
# Ideas for larger DB in csv: bigmatrix package
# dat &lt;- readRDS(&quot;C:/Users/Chris/OneDrive/R project/Open Policing/yg821jf8611_ca_statewide_2020_04_01.rds&quot;)</code></pre>
<!-- rnb-source-end -->
<p>This is my first time encountering a large dataset (3 million rows). After much stumbling in the dark and many articles I’ve linked the file to a SQLite database, made an object that is a subset of the file (20,000 rows) for initial analysis, then saved it as an RDS object that isn’t so big.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuIyBPayBTUUxpdGUgZG9lcyBub3QgaGF2ZSBhIHN0b3JhZ2UgY2xhc3MgZm9yIGRhdGVzIG9yIHRpbWVzLCBidXQgaXQgc2VlbXMgcmVhc29uYWJseSBmYXN0XG5saWJyYXJ5KGRwbHlyKVxuI1RoZSBjb2RlIGJlbG93IHNob3VsZCBvbmx5IG5lZWQgdG8gYmUgZG9uZSBvbmNlOlxuXG5cbiNmaWxlX25hbWUgPC0gXCJDYWxpZm9ybmlhX1BvbGljaW5nXCJcbiMgc3FsZGIgPC0gZGJDb25uZWN0KFNRTGl0ZSgpLCBkYm5hbWUgPSBmaWxlX25hbWUpXG4jIFdyaXRpbmdcbiMgZGJXcml0ZVRhYmxlKHNxbGRiLCBuYW1lID0gXCJDYWxmb3JuaWFfU3RhdGV3aWRlX1BvbGljaW5nXCIsIGRhdCwgcm93Lm5hbWVzID0gRkFMU0UsIG92ZXJ3cml0ZSA9IFRSVUUsIGFwcGVuZCA9IEZBTFNFLCBmaWVsZC50eXBlcyA9IE5VTEwpXG5cbiMgUmVhZGluZywgb25seSBuZWVkIHRvIGRvIG9uY2UuIFRha2luZyB0aGUgZmlyc3QgMjAsMDAwIHJvd3MuXG4jZGYgPC0gdGJsKHNxbGRiLCBcIkNhbGZvcm5pYV9TdGF0ZXdpZGVfUG9saWNpbmdcIikgJT4lIFxuIyAgc2VsZWN0KC1kYXRlLCAtcmF3X3Jvd19udW1iZXIpICU+JSBcbiMgIGZpbHRlcihyb3dfbnVtYmVyKCkgJWluJSBjKDE6MjAwMDApKSAlPiUgXG4jICBjb2xsZWN0KClcbiMgc2F2aW5nIGl0IGFzIGEgUkRTIGZpbGUgZm9yIGZ1dHVyZSB1c2VcbiMgc2F2ZVJEUyhkZixcIkM6L1VzZXJzL0NocmlzL09uZURyaXZlL1IgcHJvamVjdC9PcGVuIFBvbGljaW5nL09wZW4gUG9saWNpbmcvZGYucmRzXCIpXG4jIE9rIHRoaXMgaXMgb3VyIHJlZ3VsYXIgd29ya2luZyBvYmplY3QgZm9yIG5vdzogMjAsMDAwIHJvd3Mgb3V0IG9mIDMgbWlsbGlvbiB0byB3b3JrIHdpdGggXG5kZiA8LSByZWFkUkRTKFwiQzovVXNlcnMvQ2hyaXMvT25lRHJpdmUvUiBwcm9qZWN0L09wZW4gUG9saWNpbmcvT3BlbiBQb2xpY2luZy9kZi5yZHNcIilcbiMgZGJCZWdpbihkYikgYmVnaW5zIGEgdHJhbnNhY3Rpb25cbiMgZGJSb2xsYmFjayhkYikgcm9sbCBiYWNrIHJldmVydHMgdG8gb3JpZ2luYWwgc3RhdGVcbiMgZGJDb21taXQoZGIpICdjb21taXRzJyB0aGUgZGF0YVxuYGBgIn0= -->
<pre class="r"><code># Ok SQLite does not have a storage class for dates or times, but it seems reasonably fast
library(dplyr)
#The code below should only need to be done once:


#file_name &lt;- &quot;California_Policing&quot;
# sqldb &lt;- dbConnect(SQLite(), dbname = file_name)
# Writing
# dbWriteTable(sqldb, name = &quot;Calfornia_Statewide_Policing&quot;, dat, row.names = FALSE, overwrite = TRUE, append = FALSE, field.types = NULL)

# Reading, only need to do once. Taking the first 20,000 rows.
#df &lt;- tbl(sqldb, &quot;Calfornia_Statewide_Policing&quot;) %&gt;% 
#  select(-date, -raw_row_number) %&gt;% 
#  filter(row_number() %in% c(1:20000)) %&gt;% 
#  collect()
# saving it as a RDS file for future use
# saveRDS(df,&quot;C:/Users/Chris/OneDrive/R project/Open Policing/Open Policing/df.rds&quot;)
# Ok this is our regular working object for now: 20,000 rows out of 3 million to work with 
df &lt;- readRDS(&quot;C:/Users/Chris/OneDrive/R project/Open Policing/Open Policing/df.rds&quot;)
# dbBegin(db) begins a transaction
# dbRollback(db) roll back reverts to original state
# dbCommit(db) &#39;commits&#39; the data</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuIyBUaWRiaXQgZm9yIGZ1dHVyZSB1c2VcbiNUaGUgY29kZSBiZWxvdyBpcyBhbiBleGFtcGxlIGZvciBpZiB5b3UgbmVlZCB0byBjb3B5IGRhdGEgb3ZlciBpbnRvIGEgZGF0YWJhc2U6XG4jY29weV90byhjb24sIG55Y2ZsaWdodHMxMzo6ZmxpZ2h0cywgXCJmbGlnaHRzXCIsXG4jICB0ZW1wb3JhcnkgPSBGQUxTRSwgXG4jICBpbmRleGVzID0gbGlzdChcbiMgICAgYyhcInllYXJcIiwgXCJtb250aFwiLCBcImRheVwiKSwgXG4jICAgIFwiY2FycmllclwiLCBcbiMgICAgXCJ0YWlsbnVtXCIsXG4jICAgIFwiZGVzdFwiXG4jICApXG4jKVxuYGBgIn0= -->
<pre class="r"><code># Tidbit for future use
#The code below is an example for if you need to copy data over into a database:
#copy_to(con, nycflights13::flights, &quot;flights&quot;,
#  temporary = FALSE, 
#  indexes = list(
#    c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), 
#    &quot;carrier&quot;, 
#    &quot;tailnum&quot;,
#    &quot;dest&quot;
#  )
#)</code></pre>
<!-- rnb-source-end -->
<div id="exporatory-analysis" class="section level3">
<h3>Exporatory Analysis</h3>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShEYXRhRXhwbG9yZXIpXG5gYGAifQ== -->
<pre class="r"><code>library(DataExplorer)</code></pre>
<!-- rnb-source-end -->
<p>Going to use glimpse on the data to get a look at the data. Glimpse reveals various location, vehicle, warning, and race information. Our variables are mostly categorical, with a lot of NA’s that I might want to replace with 0’s.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZ2xpbXBzZShkZilcbmBgYCJ9 -->
<pre class="r"><code>glimpse(df)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuIyBUaGlzIGlzIHVudXNlZCBidXQgaXQncyBuaWNlIHRvIGtub3cgdGhlIHdheSB0byBmaW5kIGRhdGUgcmFuZ2VcbiNkYXQgJT4lIFxuIyAgc2VsZWN0KGRhdGUpICU+JSBcbiMgIHN1bW1hcmlzZShkYXRlX3JhbmdlID0gbWF4KGRhdGUpIC0gbWluKGRhdGUpKVxuYGBgIn0= -->
<pre class="r"><code># This is unused but it&#39;s nice to know the way to find date range
#dat %&gt;% 
#  select(date) %&gt;% 
#  summarise(date_range = max(date) - min(date))</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxucGxvdF9zdHIoZGYpXG5gYGAifQ== -->
<pre class="r"><code>plot_str(df)</code></pre>
<!-- rnb-source-end -->
<p>I’m not sure how nice this graph looks to be honest - will probably delete.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuaW50cm9kdWNlKGRmKVxuYGBgIn0= -->
<pre class="r"><code>introduce(df)</code></pre>
<!-- rnb-source-end -->
<p>Introduce is very useful, it’s telling me that there are a lot of missing values. The memory usage is in byes which is 2.5MB. Perhaps I could select more than 20,000 rows.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxucGxvdF9taXNzaW5nKGRmKVxuYGBgIn0= -->
<pre class="r"><code>plot_missing(df)</code></pre>
<!-- rnb-source-end -->
<p>Whilst the NA’s in district, county_name and search_person seem to be genuine missing data, the other variables seem to be using NA as a geuine outcome. Let’s take a look at these columns:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZGYgJT4lIHNlbGVjdChvdXRjb21lLCB3YXJuaW5nX2lzc3VlZCwgY2l0YXRpb25faXNzdWVkLCBhcnJlc3RfbWFkZSwgc2VhcmNoX2Jhc2lzLCBjb250cmFiYW5kX2ZvdW5kLCBmcmlza19wZXJmb3JtZWQpICU+JSBcbiAgZGlzdGluY3QoKVxuYGBgIn0= -->
<pre class="r"><code>df %&gt;% select(outcome, warning_issued, citation_issued, arrest_made, search_basis, contraband_found, frisk_performed) %&gt;% 
  distinct()</code></pre>
<!-- rnb-source-end -->
<p>The frisk_performed column has only NA’s and 1’s. We can treat the NA’s as 0 i.e no frisk performed. arrest_made, citation_issued, warning_issued, outcome tend to have NA’s together for a row. I believe it is a reasonable assumption that nothing occured during these pull overs. Therefore we can replace these NA’s with 0’s. The search_basis is giving us ‘other’ or NA, so we should probably remove this column. Search_person can also replace NA’s with 0’s.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuIyBNb2RpZnlpbmcgYWxsIHRoZXNlIE5BIGVudHJpZXM6XG5kZiA8LSBkZiAlPiUgXG4gIHJlcGxhY2VfbmEobGlzdChvdXRjb21lID0gXCJub3RoaW5nXCIsIHdhcm5pbmdfaXNzdWVkID0gMCwgYXJyZXN0X21hZGUgPSAwLCBjaXRhdGlvbl9pc3N1ZWQgPSAwLCB3YXJuaW5nX2lzc3VlZCA9IDAsIGNvbnRyYWJhbmRfZm91bmQgPSAwLCBmcmlza19wZXJmb3JtZWQgPSAwLCBzZWFyY2hfY29uZHVjdGVkID0gMCApKSAlPiUgXG4gIHNlbGVjdCgtc2VhcmNoX2Jhc2lzKVxuZGYgPC0gZGYgJT4lIHJlcGxhY2VfbmEobGlzdChzZWFyY2hfcGVyc29uID0gMCkpXG5gYGAifQ== -->
<pre class="r"><code># Modifying all these NA entries:
df &lt;- df %&gt;% 
  replace_na(list(outcome = &quot;nothing&quot;, warning_issued = 0, arrest_made = 0, citation_issued = 0, warning_issued = 0, contraband_found = 0, frisk_performed = 0, search_conducted = 0 )) %&gt;% 
  select(-search_basis)
df &lt;- df %&gt;% replace_na(list(search_person = 0))</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxucGxvdF9taXNzaW5nKGRmKVxuYGBgIn0= -->
<pre class="r"><code>plot_missing(df)</code></pre>
<!-- rnb-source-end -->
<p>The district and county_name entries with NA entries can be treated as unusable data, we can remove them.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZGYgPC0gZGYgJT4lIFxuICBuYS5vbWl0KClcbmBgYCJ9 -->
<pre class="r"><code>df &lt;- df %&gt;% 
  na.omit()</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxucGxvdF9taXNzaW5nKGRmKVxuYGBgIn0= -->
<pre class="r"><code>plot_missing(df)</code></pre>
<!-- rnb-source-end -->
<p>And we’re done cleaning the NA!</p>
</div>
<div id="correlation-plot" class="section level3">
<h3>Correlation plot</h3>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShwbG90bHkpXG5saWJyYXJ5KGRhdGEudGFibGUpXG5gYGAifQ== -->
<pre class="r"><code>library(plotly)
library(data.table)</code></pre>
<!-- rnb-source-end -->
<p>We want the numeric data only for the correlation matrix, but first we need to turn some categorical variables into numeric:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuSW5kdGVzdCA8LSBkZiAlPiUgXG4gIGdyb3VwX2J5KHN1YmplY3RfcmFjZSxvdXRjb21lKSAlPiUgXG4gIHN1bW1hcmlzZShuID0gbigpKSAlPiUgXG4gIHNwcmVhZChvdXRjb21lLCBuKVxuSW5kdGVzdFxuYGBgIn0= -->
<pre class="r"><code>Indtest &lt;- df %&gt;% 
  group_by(subject_race,outcome) %&gt;% 
  summarise(n = n()) %&gt;% 
  spread(outcome, n)
Indtest</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZGYgJT4lIFxuICBncm91cF9ieShzdWJqZWN0X3JhY2Usb3V0Y29tZSkgJT4lICBzdW1tYXJpc2UobiA9IG4oKSkgJT4lICBtdXRhdGUoY2hpc3FfcHZhbCA9IGNoaXNxLnRlc3QobikkcC52YWx1ZSlcbmBgYCJ9 -->
<pre class="r"><code>df %&gt;% 
  group_by(subject_race,outcome) %&gt;%  summarise(n = n()) %&gt;%  mutate(chisq_pval = chisq.test(n)$p.value)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZGYgJT4lIGRpc3RpbmN0KHN1YmplY3RfcmFjZSlcbiMgSW4gdGhlIG9yZGVyIG9mOiBhc2lhbi9pc2xhbmRlciwgYmxhY2ssIGhpc3BhbmljLCBvdGhlciwgd2hpdGVcbmRlbW8gPC0gYygwLjE0NTIrMC4wMDM2LCAwLjA1NTEsIDAuMzkyOSwgMC4wMzY4LCAwLjM2NjQpXG4jIE51bWJlcnMgYXJlIHRha2VuIGZyb20gaHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGVtb2dyYXBoaWNzX29mX0NhbGlmb3JuaWEjL21lZGlhL0ZpbGU6RXRoaWNfQ2FsaWZvcm5pYV9Pcmdhbml6ZWRfUGllLnBuZy4gVGhlIG90aGVyIGNhdGVnb3J5IEkgb2J0YWluZWQgZnJvbSAxIC0gc3VtKGRlbW8pLlxuYGBgIn0= -->
<pre class="r"><code>df %&gt;% distinct(subject_race)
# In the order of: asian/islander, black, hispanic, other, white
demo &lt;- c(0.1452+0.0036, 0.0551, 0.3929, 0.0368, 0.3664)
# Numbers are taken from https://en.wikipedia.org/wiki/Demographics_of_California#/media/File:Ethic_California_Organized_Pie.png. The other category I obtained from 1 - sum(demo).</code></pre>
<!-- rnb-source-end -->
</div>
<div id="categorical-data-analysis" class="section level3">
<h3>Categorical Data Analysis</h3>
<div id="visualising-the-covariation-between-two-categorical-variables" class="section level4">
<h4>Visualising the covariation between two categorical variables</h4>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZ2dwbG90KGRhdGEgPSBkZikgK1xuICBnZW9tX2NvdW50KG1hcHBpbmcgPSBhZXMoeCA9IHN1YmplY3RfcmFjZSwgeSA9IG91dGNvbWUsIGNvbG9yID0gLi5uLi4sIHNpemUgPSAuLm4uLikpICtcbiAgc2NhbGVfc2l6ZV9hcmVhKCkgK1xuICBzY2FsZV9zaXplX2NvbnRpbnVvdXMocmFuZ2UgPSBjKDEsMTApKSArXG4gIGdndGl0bGUoXCJDb3ZhcmlhdGlvbiBCZXR3ZWVuIE91dGNvbWUgYW5kIFJhY2VcIikgK1xuICBsYWJzKHggPVwiUmFjZSBvZiBTdWJqZWN0XCIsIHkgPSBcIk91dGNvbWVcIikgK1xuICBndWlkZXMoY29sb3IgPSBcImxlZ2VuZFwiKVxuYGBgIn0= -->
<pre class="r"><code>ggplot(data = df) +
  geom_count(mapping = aes(x = subject_race, y = outcome, color = ..n.., size = ..n..)) +
  scale_size_area() +
  scale_size_continuous(range = c(1,10)) +
  ggtitle(&quot;Covariation Between Outcome and Race&quot;) +
  labs(x =&quot;Race of Subject&quot;, y = &quot;Outcome&quot;) +
  guides(color = &quot;legend&quot;)</code></pre>
<!-- rnb-source-end -->
<p>While this is not the most informative graph, it is interesting to note that quite few direct arrests. Most of the outcomes are summons or nothing. As one can expect, the circles are largest for the hispanic and white groups - the two groups with the largest samples. Let’s do a proportion graph:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZ2dwbG90KGRhdGEgPSBkZikgK1xuICBnZW9tX2NvdW50KG1hcHBpbmcgPSBhZXMoeCA9IHN1YmplY3RfcmFjZSwgeSA9IG91dGNvbWUsIGNvbG9yID0gLi5wcm9wLi4sIHNpemUgPSAuLnByb3AuLiwgZ3JvdXAgPSAxKSkgK1xuICBzY2FsZV9zaXplX2FyZWEoKSArXG4gIHNjYWxlX3NpemVfY29udGludW91cyhyYW5nZSA9IGMoMSwxMCkpICtcbiAgZ2d0aXRsZShcIkNvdmFyaWF0aW9uIEJldHdlZW4gT3V0Y29tZSBhbmQgUmFjZVwiKSArXG4gIGxhYnMoeCA9XCJSYWNlIG9mIFN1YmplY3RcIiwgeSA9IFwiT3V0Y29tZVwiKSArXG4gIGd1aWRlcyhjb2xvciA9IFwibGVnZW5kXCIpXG5gYGAifQ== -->
<pre class="r"><code>ggplot(data = df) +
  geom_count(mapping = aes(x = subject_race, y = outcome, color = ..prop.., size = ..prop.., group = 1)) +
  scale_size_area() +
  scale_size_continuous(range = c(1,10)) +
  ggtitle(&quot;Covariation Between Outcome and Race&quot;) +
  labs(x =&quot;Race of Subject&quot;, y = &quot;Outcome&quot;) +
  guides(color = &quot;legend&quot;)</code></pre>
<!-- rnb-source-end -->
<p>Show’s the same stuff, but it’s nice to know it’s easy to go between the two. We may also be interested in a heatmap version:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZGYgJT4lIFxuICBjb3VudChzdWJqZWN0X3JhY2UsIG91dGNvbWUpICU+JSBcbmdncGxvdChhZXMoeCA9IHN1YmplY3RfcmFjZSwgeSA9IG91dGNvbWUpKSArXG4gIGdlb21fdGlsZShhZXMoZmlsbCA9IG4pKVxuYGBgIn0= -->
<pre class="r"><code>df %&gt;% 
  count(subject_race, outcome) %&gt;% 
ggplot(aes(x = subject_race, y = outcome)) +
  geom_tile(aes(fill = n))</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShocmJydGhlbWVzKVxubGlicmFyeShzZXJpYXRpb24pXG5ucm93KHVuaXF1ZShkZiAlPiUgY291bnQoc3ViamVjdF9yYWNlLG91dGNvbWUpKSlcbiMgMjVcbmNvbG91cnMgPC0gY29sb3JSYW1wUGFsZXR0ZShjKFwiYmx1ZVwiLCBcImdyZWVuXCIsIFwicmVkXCIpKSgyNSlcbmRmICU+JSBcbiAgY291bnQoc3ViamVjdF9yYWNlLCBvdXRjb21lKSAlPiUgXG5nZ3Bsb3QoYWVzKHggPSBzdWJqZWN0X3JhY2UsIHkgPSBvdXRjb21lKSkgK1xuICBnZW9tX3RpbGUoYWVzKGZpbGwgPSBuKSkgK1xuICBzY2FsZV9maWxsX2Rpc3RpbGxlcihwYWxldHRlID0gXCJSZFB1XCIpIFxuIyAgdGhlbWVfaXBzdW0oKSBtb3ZlcyBheGlzIGxhYmVscyB0byB0aGUgc2lkZVxuIyAgT3RoZXIgb3B0aW9uc1xuIyAgc2NhbGVfZmlsbF9ncmFkaWVudChsb3cgPSBcIldoaXRlXCIsIGhpZ2ggPSBcImJsdWVcIilcbiNcbiBcbiMgIHNjYWxlX2ZpbGxfYnJld2VyKHBhbGV0dGUgPSBcIlBSR25cIikgIyBzY2FsZV9maWxsX2JyZXdlciByZXF1aXJlcyBmYWN0b3IgZm9yIGZpbGwuIE9rIGl0J3MgbGltaXRlZCB0byAxMSBkaWZmZXJlbnQgZmFjb3RycyB0aGlzIGlzIGJldHRlciBmb3Igc29tZXRoaW5nIHRoYXQgaXMgZGlzY3JldGVcbmBgYCJ9 -->
<pre class="r"><code>library(hrbrthemes)
library(seriation)
nrow(unique(df %&gt;% count(subject_race,outcome)))
# 25
colours &lt;- colorRampPalette(c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))(25)
df %&gt;% 
  count(subject_race, outcome) %&gt;% 
ggplot(aes(x = subject_race, y = outcome)) +
  geom_tile(aes(fill = n)) +
  scale_fill_distiller(palette = &quot;RdPu&quot;) 
#  theme_ipsum() moves axis labels to the side
#  Other options
#  scale_fill_gradient(low = &quot;White&quot;, high = &quot;blue&quot;)
#
 
#  scale_fill_brewer(palette = &quot;PRGn&quot;) # scale_fill_brewer requires factor for fill. Ok it&#39;s limited to 11 different facotrs this is better for something that is discrete</code></pre>
<!-- rnb-source-end -->
<p>Same information is displayed but it’s definitely a more visually engaging method. The larger numbers of summons +hispanic/white really pop out. #### Test of single proportion</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZGYgJT4lIFxuICBncm91cF9ieShzdWJqZWN0X3JhY2UpICU+JSBcbiAgc3VtbWFyaXNlKG4gPSBuKCkpICU+JSBcbiAgbXV0YXRlKHJzdW0gPSBzdW0obikpXG5cbmBgYCJ9 -->
<pre class="r"><code>df %&gt;% 
  group_by(subject_race) %&gt;% 
  summarise(n = n()) %&gt;% 
  mutate(rsum = sum(n))
</code></pre>
<!-- rnb-source-end -->
<p>We can see that 1631 out of 19938 individuals pulled over were black. Wikipedia states that 5.51% of the population in CA is of black race. We can test the hypothesis that <em><span class="math inline">\(H_0:\)</span> The proportion of tested black race being 0.0551 is true </em><span class="math inline">\(H_1:\)</span> The proportion of tested black race being 0.0551 is not true</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxucHJvcC50ZXN0KDE2MzEsIDE5OTM4LCAwLjA1NTEsIGNvbmYubGV2ZWwgPSAwLjk1KVxuYGBgIn0= -->
<pre class="r"><code>prop.test(1631, 19938, 0.0551, conf.level = 0.95)</code></pre>
<!-- rnb-source-end -->
<p>The extremely low p-vale suggests we reject the null hypothesis. The estimated proportion is 0.081 with a 95% confidence interval (0.078, 0.085). This suggests that there is some bias towards selecting black drivers to be pulled over.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuIyBsaWJyYXJ5KGJyb29tKVxuZGZfY2hpc3EgPC0gZGYgJT4lIFxuICBncm91cF9ieShzdWJqZWN0X3JhY2Usb3V0Y29tZSkgJT4lICAjIHRoZSB2YXJpYWJsZXMgeW91IHdhbnQgb24gdGhlIGNvbnRlaW5nZW5jeSB0YWJsZVxuICBzdW1tYXJpc2UobiA9IG4oKSkgJT4lICMgbmVlZCB0aGUgdG90YWxzXG4gIG11dGF0ZShwcm9wb3J0aW9uID0gbi9zdW0obikpICU+JVxuICBzZWxlY3QoLXByb3BvcnRpb24pICU+JSAjIE9oIHlvdSBkZWZpbml0ZWx5IG5lZWQgdG8gZ2V0IHJpZCBvZiBwcm9wb3J0aW9uIGhlcmUgc28gaXQgc3ByZWFkcyBwcm9wZXJseVxuICBzcHJlYWQob3V0Y29tZSwgbikgJT4lICAjIGNvbnRpbmdlbmN5IHRhYmxlIG9idGFpbmVkISBBbHNvIGdvdCBwcm9wb3J0aW9ucy4uLmFuZCB0aGVuIGdvdCByaWQgb2YgdGhlbSBzaG91bGQgbWFrZSB0aGVtIHNlcGFyYXRlXG4gIHVuZ3JvdXAoKSAlPiUgIyBzZWxlY3Qgd2lsbCBub3QgcmVtb3ZlIGluIGEgZ3JvdXBlZCB0aWJibGVcbiAgc2VsZWN0KC0xKSAlPiUgXG4gIGNoaXNxLnRlc3QgIyAlPiUgXG4gIGdsYW5jZSgpXG5kZl9jaGlzcVxuYGBgIn0= -->
<pre class="r"><code># library(broom)
df_chisq &lt;- df %&gt;% 
  group_by(subject_race,outcome) %&gt;%  # the variables you want on the conteingency table
  summarise(n = n()) %&gt;% # need the totals
  mutate(proportion = n/sum(n)) %&gt;%
  select(-proportion) %&gt;% # Oh you definitely need to get rid of proportion here so it spreads properly
  spread(outcome, n) %&gt;%  # contingency table obtained! Also got proportions...and then got rid of them should make them separate
  ungroup() %&gt;% # select will not remove in a grouped tibble
  select(-1) %&gt;% 
  chisq.test # %&gt;% 
  glance()
df_chisq</code></pre>
<!-- rnb-source-end -->
<p>Testing of association between subject_race and outcome. The p-value is less than 0.05 so we reject the null hypothesis of no association and conclude that there is a association between the row variables (race) and column variables (outcome). Let’s have a look at the expected counts:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxucm91bmQoYXNfdGliYmxlKGRmX2NoaXNxJGV4cGVjdGVkKSwwKVxuYGBgIn0= -->
<pre class="r"><code>round(as_tibble(df_chisq$expected),0)</code></pre>
<!-- rnb-source-end -->
<p>Compare it to the actual counts in data:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZGYgJT4lIFxuICBncm91cF9ieShzdWJqZWN0X3JhY2Usb3V0Y29tZSkgJT4lICAjIHRoZSB2YXJpYWJsZXMgeW91IHdhbnQgb24gdGhlIGNvbnRlaW5nZW5jeSB0YWJsZVxuICBzdW1tYXJpc2UobiA9IG4oKSkgJT4lICMgbmVlZCB0aGUgdG90YWxzXG4gIG11dGF0ZShwcm9wb3J0aW9uID0gbi9zdW0obikpICU+JVxuICBzZWxlY3QoLXByb3BvcnRpb24pICU+JSAjIE9oIHlvdSBkZWZpbml0ZWx5IG5lZWQgdG8gZ2V0IHJpZCBvZiBwcm9wb3J0aW9uIGhlcmUgc28gaXQgc3ByZWFkcyBwcm9wZXJseVxuICBzcHJlYWQob3V0Y29tZSwgbikgJT4lICAjIGNvbnRpbmdlbmN5IHRhYmxlIG9idGFpbmVkISBBbHNvIGdvdCBwcm9wb3J0aW9ucy4uLmFuZCB0aGVuIGdvdCByaWQgb2YgdGhlbSBzaG91bGQgbWFrZSB0aGVtIHNlcGFyYXRlXG4gIHVuZ3JvdXAoKVxuYGBgIn0= -->
<pre class="r"><code>df %&gt;% 
  group_by(subject_race,outcome) %&gt;%  # the variables you want on the conteingency table
  summarise(n = n()) %&gt;% # need the totals
  mutate(proportion = n/sum(n)) %&gt;%
  select(-proportion) %&gt;% # Oh you definitely need to get rid of proportion here so it spreads properly
  spread(outcome, n) %&gt;%  # contingency table obtained! Also got proportions...and then got rid of them should make them separate
  ungroup()</code></pre>
<!-- rnb-source-end -->
<p>And the most contributing cells to the total chi-square score:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuc3ViamVjdF9yYWNlIDwtIGMoXCJhc2lhbi9wYWNpZmljIGlzbGFuZGVyXCIsIFwiYmxhY2tcIiwgXCJoaXNwYW5pY1wiLCBcIm90aGVyXCIsIFwid2hpdGVcIilcbmNoaXNxcmVzIDwtIGFzX3RpYmJsZShkZl9jaGlzcSRyZXNpZHVhbHMpICU+JSBhZGRfY29sdW1uKHN1YmplY3RfcmFjZSwgLmJlZm9yZSA9IDEpXG5jaGlzcXJlc1xuYGBgIn0= -->
<pre class="r"><code>subject_race &lt;- c(&quot;asian/pacific islander&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;other&quot;, &quot;white&quot;)
chisqres &lt;- as_tibble(df_chisq$residuals) %&gt;% add_column(subject_race, .before = 1)
chisqres</code></pre>
<!-- rnb-source-end -->
<p>The cells with the highest absolute standardized residuals contribute the most to the total chi-square score. Let’s visualise this:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZ2dwbG90KGRhdGEgPSBtZWx0KGNoaXNxcmVzKSwgYWVzKHggPSBzdWJqZWN0X3JhY2UseSA9IHZhcmlhYmxlICkpICtcbiAgZ2VvbV9yYXN0ZXIoYWVzKGZpbGwgPSB2YWx1ZSkpICtcbiAgc2NhbGVfZmlsbF9ncmFkaWVudChsb3cgPSBcImdyZWVuXCIsIGhpZ2ggPSBcInJlZFwiKVxuYGBgIn0= -->
<pre class="r"><code>ggplot(data = melt(chisqres), aes(x = subject_race,y = variable )) +
  geom_raster(aes(fill = value)) +
  scale_fill_gradient(low = &quot;green&quot;, high = &quot;red&quot;)</code></pre>
<!-- rnb-source-end -->
<p>It can be seen that the column black is strongly associated with summons/arrest/warning but not strongly associated with nothing and citation.</p>
</div>
</div>
<div id="classification-models" class="section level3">
<h3>Classification models</h3>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubW9kZWxfZGYgPC0gZGYgJT4lIFxuICBmaWx0ZXIocmF3X3NlYXJjaF9iYXNpcyA9PSBcIlByb2JhYmxlIENhdXNlIChwb3NpdGl2ZSlcIiB8IHJhd19zZWFyY2hfYmFzaXMgPT0gXCJQcm9iYWJsZSBDYXVzZSAobmVnYXRpdmUpXCIpICU+JSBcbiAgbXV0YXRlKGFjcm9zcyh3aGVyZShpc19jaGFyYWN0ZXIpLCBhc19mYWN0b3IpKSAlPiUgXG4gIHNlbGVjdChzdWJqZWN0X3JhY2UsIHN1YmplY3Rfc2V4LCBvdXRjb21lLCByYXdfc2VhcmNoX2Jhc2lzLCBzZWFyY2hfY29uZHVjdGVkKSBcbnNldC5zZWVkKDQyKSBcbnJvd3MgPC0gc2FtcGxlKG5yb3cobW9kZWxfZGYpKSAjIDExOTcwIHJvd3NcbiMgV2UnbGwgdXNlIHRoZSBmaXJzdCA4MDAwIHJhbmRvbWlzZWQgZW50cmllcyBmb3IgdGhlIG1vZGVsXG50cmFpbiA8LSBtb2RlbF9kZlsxOjgwMDAsIF1cbnRlc3QgPC0gbW9kZWxfZGZbODAwMToxMTk3MCwgXVxuIyBBbmQgdGhlIHJlc3QgZm9yIHRlc3Rpbmdcbm1vZGVsIDwtIGdsbShyYXdfc2VhcmNoX2Jhc2lzIH4gc3ViamVjdF9yYWNlLCBmYW1pbHkgPSBiaW5vbWlhbChsaW5rID0gXCJsb2dpdFwiKSwgZGF0YSA9IHRyYWluKVxuc3VtbWFyeShtb2RlbClcblxuXG4jIyBULXRlc3Q6IFBvcHVsYXRpb24gRGVtb2dyYXBoaWMgQ29tcGFyZWQgd2l0aCBQb2xpY2UgVGVzdGluZyBcblxuI1dlIHdhbnQgdG8gY29tcGFyZSB0aGUgcHJvcG9ydGlvbiBvZiBibGFjayBwb2xpY2luZyBpbmNpZGVudHMgdG8gdGhlIHBvcHVsYXRpb24gcHJvcG9ydGlvbi5cbmBgYCJ9 -->
<pre class="r"><code>model_df &lt;- df %&gt;% 
  filter(raw_search_basis == &quot;Probable Cause (positive)&quot; | raw_search_basis == &quot;Probable Cause (negative)&quot;) %&gt;% 
  mutate(across(where(is_character), as_factor)) %&gt;% 
  select(subject_race, subject_sex, outcome, raw_search_basis, search_conducted) 
set.seed(42) 
rows &lt;- sample(nrow(model_df)) # 11970 rows
# We&#39;ll use the first 8000 randomised entries for the model
train &lt;- model_df[1:8000, ]
test &lt;- model_df[8001:11970, ]
# And the rest for testing
model &lt;- glm(raw_search_basis ~ subject_race, family = binomial(link = &quot;logit&quot;), data = train)
summary(model)


## T-test: Population Demographic Compared with Police Testing 

#We want to compare the proportion of black policing incidents to the population proportion.</code></pre>
<!-- rnb-source-end -->
<p>We now have a model depicting the relationship between a search being positive or negative and the race of the person being pulled over. The p-values are interpreted as whether there is a difference between the log-odds of the outcome between the intercept and the explanatory variable. All of the predictors are significant using p &lt; 0.1 as the criteria but if we use p &lt; 0.05 which is more standard then the model would reject subject_raceblack as being useful in the model.</p>
<p>Let’s quickly see how R is dummy coding the variables:</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuY29udHJhc3RzKG1vZGVsX2RmJHJhd19zZWFyY2hfYmFzaXMpXG5gYGAifQ== -->
<pre class="r"><code>contrasts(model_df$raw_search_basis)</code></pre>
<!-- rnb-source-end -->
<p>Probable cause (positive) is coded as 0 while probable cause (negative) is coded as 1. We take exponential of the estimates for easier interpretation. Some of the notable interptations are:</p>
<ul>
<li>An intercept of -0.50813 implies there is a <span class="math inline">\(exp(-0.50813) = 0.60\)</span> probability that the pull-over for a hispanic is a false alarm</li>
<li>subject_raceblack estimate of 0.13792 means being black increases the log odds by 0.13792. being black has <span class="math inline">\(exp(0.13792) = 1.148\)</span> odds of being a negative false alarm than hispanics (the reference or intercept category)</li>
<li>All other groups have negative estimates and so they are more likely to be Probable Cause(positive) than hispanics
<ul>
<li>White has an estimate of -0.33708, and so <span class="math inline">\(exp(-0.33708) = 0.714\)</span> implies the average white has a <span class="math inline">\(0.6*0.714= 0.42\)</span> chance of being a Probable Cause (negative). Which means pullovers have more than a 50% chance of being correct</li>
<li>Asian/Pacific Islander has an estimate of -0.49, and so <span class="math inline">\(exp(-0.49) = 0.61\)</span> implies the average asian/pacific islander has a <span class="math inline">\(0.6*0.61 = 0.366\)</span> chance of being a Probable Cause (negative). Which means pullovers have a 36% chance of being a Probable Cause (negative). I.e most of the pullovers due to suspicion were justified</li>
</ul></li>
</ul>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuIyBTaG93aW5nIHRoaXMgaW4gcXVpY2sgdmlld1xuZXhwKGNvZWYobW9kZWwpKVxuYGBgIn0= -->
<pre class="r"><code># Showing this in quick view
exp(coef(model))</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZ2dwbG90KG1vZGVsX2RmLCBhZXMocmF3X3NlYXJjaF9iYXNpcywgZmlsbCA9IHN1YmplY3RfcmFjZSkpICtcbiAgZ2VvbV9iYXIocG9zaXRpb24gPSBcImZpbGxcIilcbmBgYCJ9 -->
<pre class="r"><code>ggplot(model_df, aes(raw_search_basis, fill = subject_race)) +
  geom_bar(position = &quot;fill&quot;)</code></pre>
<!-- rnb-source-end -->
<p>This makes sense when we look at the plot above, proportionally most of the false alarms</p>
<p>Now lets see the classification rate when we test the predictive ability of the model.</p>
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxudGVzdDEgPC0gdGVzdCAlPiUgc2VsZWN0KDEsNClcbnByb2JhYmlsaXRpZXMgPC0gIHByZWRpY3QobW9kZWwsIG5ld2RhdGEgPSB0ZXN0MSwgdHlwZSA9IFwicmVzcG9uc2VcIilcbnByZWRpY3RlZC5jbGFzcyA8LSBpZmVsc2UocHJvYmFiaWxpdGllcyA+IDAuNSwgXCJQcm9iYWJsZSBDYXVzZSAobmVnYXRpdmUpXCIsIFwiUHJvYmFibGUgQ2F1c2UgKHBvc2l0aXZlKVwiKVxuYGBgIn0= -->
<pre class="r"><code>test1 &lt;- test %&gt;% select(1,4)
probabilities &lt;-  predict(model, newdata = test1, type = &quot;response&quot;)
predicted.class &lt;- ifelse(probabilities &gt; 0.5, &quot;Probable Cause (negative)&quot;, &quot;Probable Cause (positive)&quot;)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubW9kZWxfZGZwIDwtIGRmICU+JSBcbiAgZmlsdGVyKHJhd19zZWFyY2hfYmFzaXMgPT0gXCJQcm9iYWJsZSBDYXVzZSAocG9zaXRpdmUpXCIgJiBzdWJqZWN0X3JhY2UgIT0gXCJvdGhlclwiKSAlPiUgXG4gIG11dGF0ZShhY3Jvc3Mod2hlcmUoaXNfY2hhcmFjdGVyKSwgYXNfZmFjdG9yKSkgJT4lIFxuICBzZWxlY3Qoc3ViamVjdF9yYWNlLCBzdWJqZWN0X3NleCwgb3V0Y29tZSwgcmF3X3NlYXJjaF9iYXNpcywgc2VhcmNoX2NvbmR1Y3RlZCkgXG5tb2RlbF9kZm4gPC0gZGYgJT4lIFxuICBmaWx0ZXIocmF3X3NlYXJjaF9iYXNpcyA9PSBcIlByb2JhYmxlIENhdXNlIChuZWdhdGl2ZSlcIiAmIHN1YmplY3RfcmFjZSAhPSBcIm90aGVyXCIpICU+JSBcbiAgbXV0YXRlKGFjcm9zcyh3aGVyZShpc19jaGFyYWN0ZXIpLCBhc19mYWN0b3IpKSAlPiUgXG4gIHNlbGVjdChzdWJqZWN0X3JhY2UsIHN1YmplY3Rfc2V4LCBvdXRjb21lLCByYXdfc2VhcmNoX2Jhc2lzLCBzZWFyY2hfY29uZHVjdGVkKSBcbnNldC5zZWVkKDIyMilcbmluZGV4cCA8LSBzYW1wbGUoc2VxX2xlbihucm93KG1vZGVsX2RmcCkpLCBzaXplID0gMjAwMCkgXG5pbmRleG4gPC0gc2FtcGxlKHNlcV9sZW4obnJvdyhtb2RlbF9kZm4pKSwgc2l6ZSA9IDIwMDApIFxudHJhaW4yIDwtIGJpbmRfcm93cyhtb2RlbF9kZnBbaW5kZXhwLF0sbW9kZWxfZGZuW2luZGV4bixdKVxudGVzdDIgPC0gYmluZF9yb3dzKG1vZGVsX2RmcFstaW5kZXhwLF0sbW9kZWxfZGZuWy1pbmRleG4sXSlcbm1vZGVsMiA8LSBnbG0ocmF3X3NlYXJjaF9iYXNpcyB+IHN1YmplY3RfcmFjZSwgZGF0YSA9IHRyYWluMiwgZmFtaWx5ID0gYmlub21pYWwpXG5wcm9iIDwtIG1vZGVsMiAlPiUgcHJlZGljdCh0ZXN0MiwgdHlwZSA9IFwicmVzcG9uc2VcIilcbnByZWRpY3RlZC5jbGFzcyA8LSBpZmVsc2UocHJvYiA+IDAuNSwgXCJQcm9iYWJsZSBDYXVzZSAobmVnYXRpdmUpXCIsIFwiUHJvYmFibGUgQ2F1c2UocG9zaXRpdmUpXCIpXG4jIG1lYW4ocHJlZGljdGVkLmNsYXNzID09IHRlc3QyJHJhd19zZWFyY2hfYmFzaXMpICBzb21ldGhpbmcgaXMgZ29pbmcgd3JvbmcgaGVyZS4uLmFuZCBJIGNhbid0IGZpZ3VyZSBpdCBvdXQgbXkgYnJhaW4gaHVydHNcbnRhYmxlKHByZWRpY3RlZC5jbGFzcyx0ZXN0MiRyYXdfc2VhcmNoX2Jhc2lzKSAjIEJ1dCB0aGlzIHNlZW1zIG9rXG5gYGAifQ== -->
<pre class="r"><code>model_dfp &lt;- df %&gt;% 
  filter(raw_search_basis == &quot;Probable Cause (positive)&quot; &amp; subject_race != &quot;other&quot;) %&gt;% 
  mutate(across(where(is_character), as_factor)) %&gt;% 
  select(subject_race, subject_sex, outcome, raw_search_basis, search_conducted) 
model_dfn &lt;- df %&gt;% 
  filter(raw_search_basis == &quot;Probable Cause (negative)&quot; &amp; subject_race != &quot;other&quot;) %&gt;% 
  mutate(across(where(is_character), as_factor)) %&gt;% 
  select(subject_race, subject_sex, outcome, raw_search_basis, search_conducted) 
set.seed(222)
indexp &lt;- sample(seq_len(nrow(model_dfp)), size = 2000) 
indexn &lt;- sample(seq_len(nrow(model_dfn)), size = 2000) 
train2 &lt;- bind_rows(model_dfp[indexp,],model_dfn[indexn,])
test2 &lt;- bind_rows(model_dfp[-indexp,],model_dfn[-indexn,])
model2 &lt;- glm(raw_search_basis ~ subject_race, data = train2, family = binomial)
prob &lt;- model2 %&gt;% predict(test2, type = &quot;response&quot;)
predicted.class &lt;- ifelse(prob &gt; 0.5, &quot;Probable Cause (negative)&quot;, &quot;Probable Cause(positive)&quot;)
# mean(predicted.class == test2$raw_search_basis)  something is going wrong here...and I can&#39;t figure it out my brain hurts
table(predicted.class,test2$raw_search_basis) # But this seems ok</code></pre>
<!-- rnb-source-end -->
<p>The table shows 3353 correct positive and 817 correct negative predictions. This means the model has <span class="math inline">\((3353+817)/(3353+817+882+2069) = 58.5%\)</span> chance of predicting correctly. So this model that uses a lot of the rarer data is actually decent at predicting whether someone is going to be falsely accused based on their race.</p>
</div>
<div id="section" class="section level3">
<h3></h3>
<p>This is a bad correlation graph that makes no sense that I need to either delete or edit</p>
<!-- rnb-source-begin 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 -->
<pre class="r"><code>Data_cor &lt;- df[ ,map_lgl(df, is.numeric)]

# Data_cor is the dataset (not correlation matrix) you want to use
corrdata &lt;- cor(na.omit(select_if(Data_cor, is.numeric)))
corrdata[upper.tri(corrdata, diag = TRUE)] &lt;- NA
corrdata &lt;- corrdata[-1, -ncol(corrdata)] # take out the first row (no 1-1 correlations)

# Storing variable names for later use
x_labels &lt;- colnames(corrdata)
y_labels &lt;- rownames(corrdata)

# Change variable names to numeric for the grid
colnames(corrdata) &lt;- 1:ncol(corrdata)
rownames(corrdata) &lt;- nrow(corrdata):1

# Melt the data into  the desired format
plotdata &lt;- melt(corrdata)

# Adding size variable and scaling it. $value is the correlation value
plotdata$size &lt;- (abs(plotdata$value))
scaling &lt;- 500/ncol(corrdata)/2
plotdata$size &lt;- plotdata$size*scaling 

# Setting x and y ranges for the chart
# We used unit values for initial grid, so shift by 0.5 to create gridlines
xrange &lt;- c(0.5, length(x_labels) + 0.5)
yrange &lt;- c(0.5, length(y_labels) + 0.5)

# Setting the gridlines
x_grid &lt;- seq(1.5, length(x_labels) - 0.5, 1)
y_grid &lt;- seq(1.5, length(x_labels) - 0.5, 1)

# Now some cleanup. Naming variables and removing gridlines

xAx1 &lt;- list(showgrid = FALSE, showline = FALSE, zeroline = FALSE, tickvals = colnames(corrdata), ticktext = x_labels, title = FALSE)

xAx2 &lt;- list(showgrid = FALSE, showline = FALSE, zeroline = FALSE, overlaying = &quot;x&quot;, showticklabels = FALSE, range = xrange, tickvals = x_grid)

yAx1 &lt;- list(autoaxis = FALSE, showgrid  = FALSE, showline = FALSE, zeroline = FALSE, tickvals = rownames(corrdata), ticktext = y_labels, title = FALSE)

yAx2 &lt;- list(showgrid = TRUE, showline = FALSE, zeroline = FALSE, overlaying = &quot;y&quot;, showticklabels = FALSE, range = yrange, tickvals = y_grid)

fig &lt;- plot_ly(data = plotdata, width = 500, height = 500)

fig &lt;- fig %&gt;% add_trace(x = ~Var2, y = ~Var1, type = &quot;scatter&quot;, mode = &quot;markers&quot;,
                        color = ~value,
                        marker = list(size = ~size, opacity = 1),
                        symbol = I(&quot;square&quot;),
                        text = ~value,
                        hovertemplate = &quot;%{text:.2f} &lt;extra&gt;&lt;/extra&gt;&quot;,
                        xaxis = &quot;x1&quot;,
                        yaxis = &quot;y1&quot;)

fig &lt;- fig %&gt;% add_trace(x = ~Var2, y = ~Var1, type = &quot;scatter&quot;, mode = &quot;markers&quot;,
                        opacity = 0,
                        showlegend = FALSE,
                        xaxis = &quot;x2&quot;,
                        yaxis = &quot;y2&quot;,
                        hoverinfo = &quot;none&quot;)

fig &lt;- fig %&gt;% layout(xaxis = xAx1,
                     yaxis = yAx1, 
                     xaxis2 = xAx2,
                     yaxis2 = yAx2,
                     plot_bgcolor = &quot;rgba(0,0,0,0)&quot;,
                     paper_bgcolor = &quot;rgba(0, 0, 0, 0.03)&quot;)

fig &lt;- fig %&gt;% colorbar(title = &quot;&quot;, limits = c(-1,1), x = 1.1, y = 0.75)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuZmlnXG5gYGAifQ== -->
<pre class="r"><code>fig</code></pre>
<!-- rnb-source-end -->
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
